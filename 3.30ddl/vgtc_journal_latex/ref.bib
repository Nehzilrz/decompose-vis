
@online{_automated_????,
	title = {Automated Hypothesis Generation Based on Mining Scientific Literature},
	url = {http://delivery.acm.org/10.1145/2630000/2623667/p1877-spangler.pdf?ip=175.159.124.243&id=2623667&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864115377&CFTOKEN=71278738&__acm__=1478936347_b2011b04ad609a52e8ed92eb1e256cad},
	urldate = {2016-11-12},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GEF4HCFQ/p1877-spangler.html:text/html;拍877.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7VK5NCEN/拍877.pdf:application/pdf}
}

@article{dunne_rapid_2012,
	title = {Rapid understanding of scientific paper collections: Integrating statistics, text analytics, and visualization},
	volume = {63},
	issn = {1532-2890},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/asi.22652/abstract},
	doi = {10.1002/asi.22652},
	shorttitle = {Rapid understanding of scientific paper collections},
	abstract = {Keeping up with rapidly growing research fields, especially when there are multiple interdisciplinary sources, requires substantial effort for researchers, program managers, or venture capital investors. Current theories and tools are directed at finding a paper or website, not gaining an understanding of the key papers, authors, controversies, and hypotheses. This report presents an effort to integrate statistics, text analytics, and visualization in a multiple coordinated window environment that supports exploration. Our prototype system, Action Science Explorer ({ASE}), provides an environment for demonstrating principles of coordination and conducting iterative usability tests of them with interested and knowledgeable users. We developed an understanding of the value of reference management, statistics, citation text extraction, natural language summarization for single and multiple documents, filters to interactively select key papers, and network visualization to see citation patterns and identify clusters. A three-phase usability study guided our revisions to {ASE} and led us to improve the testing methods.},
	pages = {2351--2369},
	number = {12},
	journaltitle = {Journal of the American Society for Information Science and Technology},
	shortjournal = {J Am Soc Inf Sci Tec},
	author = {Dunne, Cody and Shneiderman, Ben and Gove, Robert and Klavans, Judith and Dorr, Bonnie},
	urldate = {2016-11-12},
	date = {2012-12-01},
	langid = {english},
	keywords = {graphs, Natural Language Processing, visualization (electronic)},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4HI7GQP2/Dunne 等. - 2012 - Rapid understanding of scientific paper collection.pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/ZEC83QP2/abstract.html:text/html}
}

@article{bigelow_iterating_2016,
	title = {Iterating Between Tools to Create and Edit Visualizations},
	volume = {{PP}},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598609},
	abstract = {A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, datadriven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.},
	pages = {1--1},
	number = {99},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bigelow, A. and Drucker, S. and Fisher, D. and Meyer, M.},
	date = {2016},
	keywords = {Bridges, Data visualization, illustration, Image color analysis, iteration, Manuals, Software, Solid modeling, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IKJVRBPV/7539580.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/AS6V4BCB/Bigelow 等. - 2016 - Iterating Between Tools to Create and Edit Visuali.pdf:application/pdf}
}

@article{treisman_feature-integration_1980,
	title = {A feature-integration theory of attention},
	volume = {12},
	issn = {0010-0285},
	url = {http://www.sciencedirect.com/science/article/pii/0010028580900055},
	doi = {10.1016/0010-0285(80)90005-5},
	abstract = {A new hypothesis about the role of focused attention is proposed. The feature-integration theory of attention suggests that attention must be directed serially to each stimulus in a display whenever conjunctions of more than one separable feature are needed to characterize or distinguish the possible objects presented. A number of predictions were tested in a variety of paradigms including visual search, texture segregation, identification and localization, and using both separable dimensions (shape and color) and local elements or parts of figures (lines, curves, etc. in letters) as the features to be integrated into complex wholes. The results were in general consistent with the hypothesis. They offer a new set of criteria for distinguishing separable from integral features and a new rationale for predicting which tasks will show attention limits and which will not.},
	pages = {97--136},
	number = {1},
	journaltitle = {Cognitive Psychology},
	shortjournal = {Cognitive Psychology},
	author = {Treisman, Anne M. and Gelade, Garry},
	urldate = {2017-01-17},
	date = {1980-01},
	file = {ScienceDirect Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/NTZUGX9D/0010028580900055.html:text/html}
}

@article{wolfe_guided_1994,
	title = {Guided Search 2.0 A revised model of visual search},
	volume = {1},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/article/10.3758/BF03200774},
	doi = {10.3758/BF03200774},
	abstract = {An important component of routine visual behavior is the ability to find one item in a visual world filled with other, distracting items. This ability to performvisual search has been the subject of a large body of research in the past 15 years. This paper reviews the visual search literature and presents a model of human search behavior. Built upon the work of Neisser, Treisman, Julesz, and others, the model distinguishes between a preattentive, massively parallel stage that processes information about basic visual features (color, motion, various depth cues, etc.) across large portions of the visual field and a subsequent limited-capacity stage that performs other, more complex operations (e.g., face recognition, reading, object identification) over a limited portion of the visual field. The spatial deployment of the limited-capacity process is under attentional control. The heart of the guided search model is the idea that attentional deployment of limited resources isguided by the output of the earlier parallel processes. Guided Search 2.0 ({GS}2) is a revision of the model in which virtually all aspects of the model have been made more explicit and/or revised in light of new data. The paper is organized into four parts: Part 1 presents the model and the details of its computer simulation. Part 2 reviews the visual search literature on preattentive processing of basic features and shows how the {GS}2 simulation reproduces those results. Part 3 reviews the literature on the attentional deployment of limited-capacity processes in conjunction and serial searches and shows how the simulation handles those conditions. Finally, Part 4 deals with shortcomings of the model and unresolved issues.},
	pages = {202--238},
	number = {2},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychonomic Bulletin \& Review},
	author = {Wolfe, Jeremy M.},
	urldate = {2017-01-17},
	date = {1994-06-01},
	langid = {english},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/MEH2N525/Wolfe - 1994 - Guided Search 2.0 A revised model of visual search.pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/FUI6FP2P/BF03200774.html:text/html}
}

@article{borkin_what_2013,
	title = {What Makes a Visualization Memorable?},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.234},
	abstract = {An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.},
	pages = {2306--2315},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Borkin, M. A. and Vo, A. A. and Bylinskii, Z. and Isola, P. and Sunkavalli, S. and Oliva, A. and Pfister, H.},
	date = {2013-12},
	keywords = {Amazon, Artificial Intelligence, Cues, data-ink ratios, data understanding, data visualisation, Data visualization, Encoding, government reports, Humans, Image Interpretation, Computer-Assisted, infographic sources, Information technology, information visualization, Mechanical Turk, memorability, memorability scores, Memory, news media sites, Pattern Recognition, Visual, scientific journals, Task Performance and Analysis, Taxonomy, User-Computer Interface, visual densities, visualization community, Visualization taxonomy, visualization type},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TI8R9V53/6634103.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/V6NHQUXV/Borkin 等. - 2013 - What Makes a Visualization Memorable.pdf:application/pdf}
}

@article{bryan_temporal_2016,
	title = {Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement},
	volume = {{PP}},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598876},
	shorttitle = {Temporal Summary Images},
	abstract = {Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest ({POIs}). We present Temporal Summary Images ({TSIs}) as an approach for both exploring this data and creating stories from it. As a visualization, a {TSI} is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for {TSIs} to conduct two case studies with large-scale, scientific simulation datasets.},
	pages = {1--1},
	number = {99},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bryan, C. and Ma, K. L. and Woodring, J.},
	date = {2016},
	keywords = {Additives, annotations, comic strip visualization, Context, data analysis, Data visualization, Layout, Narrative visualization, storytelling, Strips, time-varying data, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DGNJ8N38/7539294.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6PNWJ4JP/Bryan 等. - 2016 - Temporal Summary Images An Approach to Narrative .pdf:application/pdf}
}

@online{wang_guided_????,
	title = {A Guided Tour of Literature Review: Facilitating Academic Paper Reading with Narrative Visualization},
	url = {http://www.cse.ust.hk/~ywangch/vispaper.pdf},
	author = {wang, yun and Liu, dongyu},
	urldate = {2016-11-06},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PQBUCJCJ/vispaper.html:text/html;vispaper.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/9QX68PD5/vispaper.pdf:application/pdf}
}

@article{lee_more_2015,
	title = {More Than Telling a Story: Transforming Data into Visually Shared Stories},
	volume = {35},
	issn = {0272-1716},
	doi = {10.1109/MCG.2015.99},
	shorttitle = {More Than Telling a Story},
	abstract = {The authors take a closer look at how the visualization community has discussed visual storytelling and present a visual data storytelling process, incorporating steps involved in finding insights (explore data), turning these insights into a narrative (make a story), and communicating this narrative to an audience (tell a story). They also discuss opportunities for future research in visualization as a storytelling medium in the light of this broader process.},
	pages = {84--90},
	number = {5},
	journaltitle = {{IEEE} Computer Graphics and Applications},
	author = {Lee, B. and Riche, N. H. and Isenberg, P. and Carpendale, S.},
	date = {2015-09},
	keywords = {communication, Computer Graphics, Context awareness, data analysis, data transformation, data visualisation, Data visualization, Media, Narratives, Narrative visualization, presentation, Professional communication, Programming, storytelling, storytelling process, visual data story, visual data storytelling process, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GIXPHA4A/7274435.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H8SSG6KN/Lee 等. - 2015 - More Than Telling a Story Transforming Data into .pdf:application/pdf}
}

@article{hullman_visualization_2011,
	title = {Visualization Rhetoric: Framing Effects in Narrative Visualization},
	volume = {17},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2011.255},
	shorttitle = {Visualization Rhetoric},
	abstract = {Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that "tell a story" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation.},
	pages = {2231--2240},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Hullman, J. and Diakopoulos, N.},
	date = {2011-12},
	keywords = {communicative information visualization, connotation., critical theory, data visualisation, Data visualization, decision making, denotation, design tactics, end-user interpretation, exploratory information visualization, framing effects, journalism, literary study, narrative information visualization, Narrative visualization, political messaging, political theory, Rhetoric, semiotics, textual annotation, visualization rhetoric, visual representation, wait for reading},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/UVQ23A94/6064988.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2SJ6CART/Hullman 和 Diakopoulos - 2011 - Visualization Rhetoric Framing Effects in Narrati.pdf:application/pdf}
}

@article{borkin_beyond_2016,
	title = {Beyond Memorability: Visualization Recognition and Recall},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467732},
	shorttitle = {Beyond Memorability},
	abstract = {In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable “at-a-glance” are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one.},
	pages = {519--528},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Borkin, M. A. and Bylinskii, Z. and Kim, N. W. and Bainbridge, C. M. and Yeh, C. S. and Borkin, D. and Pfister, H. and Oliva, A.},
	date = {2016-01},
	keywords = {0, Atmospheric measurements, data visualisation, Data visualization, Encoding, eye-tracking study, information visualization, memorability, participant-generated text description, Particle measurements, qualitative design guidelines, recall, recognition, Redundancy, Target recognition, Visualization, visualization message, visualization recall, visualization recognition},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/MICWQURA/7192646.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/UR6BRDHB/Borkin 等. - 2016 - Beyond Memorability Visualization Recognition and.pdf:application/pdf}
}

@article{brehmer_timelines_2016,
	title = {Timelines Revisited: A Design Space and Considerations for Expressive Storytelling},
	volume = {{PP}},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2614803},
	shorttitle = {Timelines Revisited},
	abstract = {There are many ways to visualize event sequences as timelines. In a storytelling context where the intent is to convey multiple narrative points, a richer set of timeline designs may be more appropriate than the narrow range that has been used for exploratory data analysis by the research community. Informed by a survey of 263 timelines, we present a design space for storytelling with timelines that balances expressiveness and effectiveness, identifying 14 design choices characterized by three dimensions: representation, scale, and layout. Twenty combinations of these choices are viable timeline designs that can be matched to different narrative points, while smooth animated transitions between narrative points allow for the presentation of a cohesive story, an important aspect of both interactive storytelling and data videos. We further validate this design space by realizing the full set of viable timeline designs and transitions in a proof-of-concept sandbox implementation that we used to produce seven example timeline stories. Ultimately, this work is intended to inform and inspire the design of future tools for storytelling with timelines.},
	pages = {1--1},
	number = {99},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Brehmer, M. and Lee, B. and Bach, B. and Riche, N. Henry and Munzner, T.},
	date = {2016},
	keywords = {animated transitions, Biographies, Context, Data visualization, design space, history, Layout, Narrative visualization, storytelling, Timelines, Videos, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QAP8UZNA/7581076.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H54R88FG/Brehmer 等. - 2016 - Timelines Revisited A Design Space and Considerat.pdf:application/pdf}
}

@online{_summarizing_????,
	title = {Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status},
	url = {http://www.mitpressjournals.org/doi/pdf/10.1162/089120102762671936},
	urldate = {2016-11-19},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2VWG3JQK/089120102762671936.html:text/html;089120102762671936.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/9TV57P7V/089120102762671936.pdf:application/pdf}
}

@inproceedings{kuhn_codetimeline:_2012,
	title = {{CodeTimeline}: Storytelling with versioning data},
	doi = {10.1109/ICSE.2012.6227086},
	shorttitle = {{CodeTimeline}},
	abstract = {Working with a software system typically requires knowledge of the system's history, however this knowledge is often only tribal memory of the development team. In past user studies we have observed that when being presented with collaboration views and word clouds from the system's history engineers start sharing memories linked to those visualizations. In this paper we propose an approach based on a storytelling visualization, which is designed to entice engineers to share and document their tribal memory. Sticky notes can be used to share memories of a system's lifetime events, such as past design rationales but also more casual memories like pictures from after-work beer or a hackathon. We present an early-stage prototype implementation and include two design studies created using that prototype.},
	eventtitle = {2012 34th International Conference on Software Engineering ({ICSE})},
	pages = {1333--1336},
	booktitle = {2012 34th International Conference on Software Engineering ({ICSE})},
	author = {Kuhn, A. and Stocker, M.},
	date = {2012-06},
	keywords = {codetimeline, Collaboration, collaboration views, data visualisation, Data visualization, early-stage prototype implementation, history, humanities, Humans and Social Aspects, program visualisation, Prototypes, Software, Software Evolution, software system, Software Visualization, Sticky notes, storytelling visualization, Tag clouds, Tools and Environments, tribal memory, versioning data, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/BDK6IJTP/6227086.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CTUXDN8F/Kuhn 和 Stocker - 2012 - CodeTimeline Storytelling with versioning data.pdf:application/pdf}
}

@article{kosara_storytelling:_2013,
	title = {Storytelling: The Next Step for Visualization},
	volume = {46},
	issn = {0018-9162},
	doi = {10.1109/MC.2013.36},
	shorttitle = {Storytelling},
	abstract = {Presentation-specifically, its use of elements from storytelling-is the next logical step in visualization research and should be a focus of at least equal importance with exploration and analysis.},
	pages = {44--50},
	number = {5},
	journaltitle = {Computer},
	author = {Kosara, R. and Mackinlay, J.},
	date = {2013-05},
	keywords = {Collaboration, data visualisation, Data visualization, Narratives, presentation, storytelling, visual communication, Visual databases, Visual effects, Visualization, visualization research},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/ZPJJSXJQ/6412677.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/K649TBJV/Kosara 和 Mackinlay - 2013 - Storytelling The Next Step for Visualization.pdf:application/pdf}
}

@online{_storytelling_????,
	title = {Storytelling in Visual Analytics Tools for Business Intelligence},
	url = {http://download.springer.com/static/pdf/473/chp%253A10.1007%252F978-3-642-40477-1_18.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-642-40477-1_18&token2=exp=1479549295~acl=%2Fstatic%2Fpdf%2F473%2Fchp%25253A10.1007%25252F978-3-642-40477-1_18.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F978-3-642-40477-1_18*~hmac=16d5278a3c7dcf91b1600716d24a373c4ebf46d33a265f0a856e61526051b899},
	urldate = {2016-11-19},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7KVSKRIB/chp%3A10.1007%2F978-3-642-40477-1_18.html:text/html;chp%3A10.1007%2F978-3-642-40477-1_18.html:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QKU6AF9G/chp%3A10.1007%2F978-3-642-40477-1_18.html:text/html;chp%253A10.1007%252F978-3-642-40477-1_18.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IP56VEKA/chp%253A10.1007%252F978-3-642-40477-1_18.pdf:application/pdf}
}

@online{_automated_????-1,
	title = {Automated Interactive Narrative Synthesis using Dramatic Theory},
	url = {http://delivery.acm.org/10.1145/2830000/2822028/p103-dominguez.pdf?ip=175.159.124.243&id=2822028&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1480045870_f953283e45512d29948f9fcff8e0f18f},
	urldate = {2016-11-25},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/XH5J2A4G/p103-dominguez.html:text/html;p103-dominguez.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H5H6BB7Z/p103-dominguez.pdf:application/pdf}
}

@online{_digestmanga:_????,
	title = {{DigestManga}: Interactive Movie Summarizing through Comic Visualization},
	url = {http://delivery.acm.org/10.1145/1760000/1754050/p3751-tobita.pdf?ip=175.159.124.243&id=1754050&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1480252920_606328c3fd7fb1931880a3373ba1a337},
	urldate = {2016-11-27},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/NZB462GU/p3751-tobita.html:text/html;p3751-tobita.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2KUZC3W6/p3751-tobita.pdf:application/pdf}
}

@online{_interactive_????,
	title = {Interactive Multimedia Summaries of Evaluative Text},
	url = {http://delivery.acm.org/10.1145/1120000/1111480/p124-carenini.pdf?ip=175.159.124.243&id=1111480&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1480253074_b1d8e5f4b21ee7cdbfb208276d4b8dd4},
	urldate = {2016-11-27},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/W5FG6B2I/p124-carenini.html:text/html;p124-carenini.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RSQ8298P/p124-carenini.pdf:application/pdf}
}

@inproceedings{dou_leadline:_2012,
	title = {{LeadLine}: Interactive visual analysis of text data through event identification and exploration},
	doi = {10.1109/VAST.2012.6400485},
	shorttitle = {{LeadLine}},
	abstract = {Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, {LeadLine}, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, {LeadLine} integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, {LeadLine} allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, {LeadLine} provides a concise summary of the corpora. {LeadLine} also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of {LeadLine} in identifying events and supporting exploration, two case studies were conducted using news and social media data.},
	eventtitle = {2012 {IEEE} Conference on Visual Analytics Science and Technology ({VAST})},
	pages = {93--102},
	booktitle = {2012 {IEEE} Conference on Visual Analytics Science and Technology ({VAST})},
	author = {Dou, W. and Wang, X. and Skau, D. and Ribarsky, W. and Zhou, M. X.},
	date = {2012-10},
	keywords = {automatically identify meaningful events, Crawlers, data mining, entity recognition techniques, Event detection, event exploration, event identification, information extraction, information retrieval, interactive visual analysis, interactive visual analytics system, large-scale text corpora, Lead, {LeadLine}, microblogs, news data, online news, social media data, social networking (online), support exploration, text analysis, text data, Time series analysis, Twitter, Visualization, visual text analysis systems},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/Z9FC6EUR/6400485.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DAHCXEJ9/Dou 等. - 2012 - LeadLine Interactive visual analysis of text data.pdf:application/pdf}
}

@article{isenberg_visualization_2017,
	title = {Visualization as Seen through its Research Paper Keywords},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598827},
	abstract = {We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the {IEEE} Visualization conference series (now called {IEEE} {VIS}) between 1990–2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the {IEEE} {VIS} reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for {IEEE} {VIS} papers since 1990 to find related work or make informed keyword choices.},
	pages = {771--780},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Isenberg, P. and Isenberg, T. and Sedlmair, M. and Chen, J. and M?ller, T.},
	date = {2017-01},
	keywords = {data analysis, data mining, Data models, Data visualization, Market research, research themes, research topics, Taxonomy, theory, Visualization, visualization history, vocabulary},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/KAJWX9UG/7539364.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/KKPVZ27X/Isenberg 等. - 2017 - Visualization as Seen through its Research Paper K.pdf:application/pdf}
}

@article{amini_authoring_2017,
	title = {Authoring Data-Driven Videos with {DataClips}},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598647},
	abstract = {Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce {DataClips}, an authoring tool aimed at lowering the barriers to crafting data videos. {DataClips} allows non-experts to assemble data-driven “clips” together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that {DataClips} can reproduce over 90\% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using {DataClips}, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use {DataClips} with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience.},
	pages = {501--510},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Amini, F. and Riche, N. H. and Lee, B. and Monroy-Hernandez, A. and Irani, P.},
	date = {2017-01},
	keywords = {Animation, authoring tools, data storytelling, data video, Data visualization, Libraries, Media, Narrative visualization, Videos, Visualization, visualization systems},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PF6QKW6E/7539370.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/N54XWJXI/Amini 等. - 2017 - Authoring Data-Driven Videos with DataClips.pdf:application/pdf}
}

@online{_emerging_????,
	title = {Emerging and Recurring Data-Driven Storytelling Techniques: Analysis of a Curated Collection of Recent Stories},
	url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/MSR-TR-2016-14-Storytelling-Techniques-1.pdf},
	urldate = {2017-01-08},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/NTM8CJ8M/MSR-TR-2016-14-Storytelling-Techniques-1.html:text/html;MSR-TR-2016-14-Storytelling-Techniques-1.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U364SNPQ/MSR-TR-2016-14-Storytelling-Techniques-1.pdf:application/pdf}
}

@article{hullman_deeper_2013,
	title = {A Deeper Understanding of Sequence in Narrative Visualization},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.119},
	abstract = {Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.},
	pages = {2406--2415},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Hullman, J. and Drucker, S. and Riche, N. Henry and Lee, B. and Fisher, D. and Adar, E.},
	date = {2013-12},
	keywords = {Algorithms, Artificial Intelligence, audience perspective, automatic effective sequence identification, cognition, Comprehension, Computer Graphics, data storytelling, data visualisation, Data visualization, Encoding, global sequencing strategies, graph-driven approach, graph theory, humanities, Humans, Linear programming, local transitions, Multimodal Imaging, Narration, narrative sequencing, narrative structure, narrative systems, Narrative visualization, Parallel processing, Pattern Recognition, Visual, professional narrative visualizations, qualitative analysis, Reproducibility of Results, Sensitivity and Specificity, sequences, Sequential analysis, slideshow-style presentations, User-Computer Interface, user preferences, visualization sequence optimization, visualization set, visualization-to-visualization transitions, Visual Perception},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/E7ESNZEM/6634182.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U5XJD88A/Hullman 等. - 2013 - A Deeper Understanding of Sequence in Narrative Vi.pdf:application/pdf}
}

@article{bach_graphdiaries:_2014,
	title = {{GraphDiaries}: Animated Transitions {andTemporal} Navigation for Dynamic Networks},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.254},
	shorttitle = {{GraphDiaries}},
	abstract = {Identifying, tracking and understanding changes in dynamic networks are complex and cognitively demanding tasks. We present {GraphDiaries}, a visual interface designed to improve support for these tasks in any node-link based graph visualization system. {GraphDiaries} relies on animated transitions that highlight changes in the network between time steps, thus helping users identify and understand those changes. To better understand the tasks related to the exploration of dynamic networks, we first introduce a task taxonomy, that informs the design of {GraphDiaries}, presented afterwards. We then report on a user study, based on representative tasks identified through the taxonomy, and that compares {GraphDiaries} to existing techniques for temporal navigation in dynamic networks, showing that it outperforms them in terms of both task time and errors for several of these tasks.},
	pages = {740--754},
	number = {5},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bach, B. and Pietriga, E. and Fekete, J. D.},
	date = {2014-05},
	keywords = {animated transitions, Animation, Complexity theory, computer animation, data visualisation, dynamic networks, {GraphDiaries}, graphical user interfaces, graph theory, Graph Visualization, Layout, Navigation, network theory (graphs), node-link-based graph visualization system, task errors, task taxonomy, task time, Taxonomy, temporal navigation, time steps, Topology, user experiment, visual interface, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/R7QJX9T6/6658746.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6DBB7TUH/Bach 等. - 2014 - GraphDiaries Animated Transitions andTemporal Nav.pdf:application/pdf}
}

@inproceedings{eccles_stories_2007,
	title = {Stories in {GeoTime}},
	doi = {10.1109/VAST.2007.4388992},
	abstract = {A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in {GeoTime}. The {GeoTime} geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.},
	eventtitle = {2007 {IEEE} Symposium on Visual Analytics Science and Technology},
	pages = {19--26},
	booktitle = {2007 {IEEE} Symposium on Visual Analytics Science and Technology},
	author = {Eccles, R. and Kapler, T. and Harper, R. and Wright, W.},
	date = {2007-10},
	keywords = {analytic sense-making cohesion, Collaboration, Context, data mining, data visualisation, Data visualization, Event detection, geographic information systems, {GeoTime} geo-temporal event visualization tool, graphical user interfaces, human information interaction, humanities, Humans, hypertext linked visualization, Information analysis, narrative, Pattern analysis, pattern detection, sense-making, story making, story system, story telling, Visual analytics, visual annotation},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/8CKP5RCR/4388992.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/C54CQI3S/Eccles 等. - 2007 - Stories in GeoTime.pdf:application/pdf}
}

@online{_mylifebits:_????,
	title = {{MyLifeBits}: A Personal Database for Everything},
	url = {http://delivery.acm.org/10.1145/1110000/1107460/p88-gemmell.pdf?ip=175.159.124.243&id=1107460&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1483929851_94ae270093b0559ad7632e73037354ce},
	urldate = {2017-01-09},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IJDMNVI2/p88-gemmell.html:text/html}
}

@online{_lifelines:_????,
	title = {{LifeLines}: Visualizing Personal Histories},
	url = {http://delivery.acm.org/10.1145/240000/238493/p221-plaisant.pdf?ip=175.159.124.243&id=238493&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1483930263_e1115093b24d2dc28be2c214291f5e81},
	urldate = {2017-01-09},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/R3X7DJCE/p221-plaisant.html:text/html;p221-plaisant.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/MVZEM8F4/p221-plaisant.pdf:application/pdf}
}

@online{_automatic_????,
	title = {Automatic generation of visual story for fairy tales with digital narrative},
	url = {http://content.iospress.com/download/web-intelligence/web314?id=web-intelligence%2Fweb314},
	urldate = {2017-01-09},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TMV6A5RV/web314.html:text/html}
}

@online{_meseum:_????,
	title = {{MEseum}: Personalized Experience with Narrative Visualization for Museum Visitors},
	url = {http://download.springer.com/static/pdf/906/chp%253A10.1007%252F978-3-319-39513-5_17.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-319-39513-5_17&token2=exp=1483947550~acl=%2Fstatic%2Fpdf%2F906%2Fchp%25253A10.1007%25252F978-3-319-39513-5_17.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F978-3-319-39513-5_17*~hmac=3acaaccc59aedc862b49311e75258fd6eabfe5bee290404dda7c1f4fc6628c05},
	urldate = {2017-01-09},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GTVFDRUZ/chp%3A10.1007%2F978-3-319-39513-5_17.html:text/html}
}

@inproceedings{kucher_text_2015,
	title = {Text visualization techniques: Taxonomy, visual survey, and community insights},
	doi = {10.1109/PACIFICVIS.2015.7156366},
	shorttitle = {Text visualization techniques},
	abstract = {Text visualization has become a growing and increasingly important subfield of information visualization. Thus, it is getting harder for researchers to look for related work with specific tasks or visual metaphors in mind. In this paper, we present an interactive visual survey of text visualization techniques that can be used for the purposes of search for related work, introduction to the subfield and gaining insight into research trends. We describe the taxonomy used for categorization of text visualization techniques and compare it to approaches employed in several other surveys. Finally, we present results of analyses performed on the entries data.},
	eventtitle = {2015 {IEEE} Pacific Visualization Symposium ({PacificVis})},
	pages = {117--121},
	booktitle = {2015 {IEEE} Pacific Visualization Symposium ({PacificVis})},
	author = {Kucher, K. and Kerren, A.},
	date = {2015-04},
	keywords = {Browsers, categorization taxonomy, community analysis, community insight, data analysis, data visualisation, Data visualization, Interaction, interactive systems, interactive visual survey, Market research, Media, pattern classification, survey, Taxonomy, text analysis, Text visualization, text visualization technique, Visualization, web-based systems},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/73RJG4JZ/7156366.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/34CFJQBB/Kucher 和 Kerren - 2015 - Text visualization techniques Taxonomy, visual su.pdf:application/pdf}
}

@article{he_vizitcards:_2017,
	title = {{VizItCards}: A Card-Based Toolkit for Infovis Design Education},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2599338},
	shorttitle = {{VizItCards}},
	abstract = {Shifts in information visualization practice are forcing a reconsideration of how infovis is taught. Traditional curricula that focused on conveying research-derived knowledge are slowly integrating design thinking as a key learning objective. In part, this is motivated by the realization that infovis is a wicked design problem, requiring a different kind of design work. In this paper we describe, {VizItCards}, a card-driven workshop developed for our graduate infovis class. The workshop is intended to provide practice with good design techniques and to simultaneously reinforce key concepts. {VizItCards} relies on principles of collaborative-learning and research on parallel design to generate positive collaborations and high-quality designs. From our experience of simulating a realistic design scenario in a classroom setting, we find that our students were able to meet key learning objectives and their design performance improved during the class. We describe variants of the workshop, discussing which techniques we think match to which learning goals.},
	pages = {561--570},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {He, S. and Adar, E.},
	date = {2017-01},
	keywords = {card, card-based toolkit, card-driven workshop, Collaboration, collaborative-learning, computer aided instruction, Conferences, data visualisation, Data visualization, design workshop, Education, Human computer interaction, information visualization education, infovis design education, parallel design, peer learning, Standards, toolkit, Visualization, {VizItCards}},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/3HFFE77E/7539629.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/ZQK7V9AJ/He 和 Adar - 2017 - VizItCards A Card-Based Toolkit for Infovis Desig.pdf:application/pdf}
}

@article{robertson_effectiveness_2008,
	title = {Effectiveness of Animation in Trend Visualization},
	volume = {14},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2008.125},
	abstract = {Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.},
	pages = {1325--1332},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Robertson, G. and Fernandez, R. and Fisher, D. and Lee, B. and Stasko, J.},
	date = {2008-11},
	keywords = {Animation, computer animation, data analysis, data visualisation, Data visualization, design, Dictionaries, Displays, experiment, Gapminder Trendalyzer, Index Terms—Information visualization, trend animation, trends, trend visualization, wait for reading},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GSP7B7E3/4658146.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/48QAZVMR/Robertson 等. - 2008 - Effectiveness of Animation in Trend Visualization.pdf:application/pdf}
}

@article{waldner_attractive_2014,
	title = {Attractive Flicker \#x2014; Guiding Attention in Dynamic Narrative Visualizations},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346352},
	abstract = {Focus-context techniques provide visual guidance in visualizations by giving strong visual prominence to elements of interest while the context is suppressed. However, finding a visual feature to enhance for the focus to pop out from its context in a large dynamic scene, while leading to minimal visual deformation and subjective disturbance, is challenging. This paper proposes Attractive Flicker, a novel technique for visual guidance in dynamic narrative visualizations. We first show that flicker is a strong visual attractor in the entire visual field, without distorting, suppressing, or adding any scene elements. The novel aspect of our Attractive Flicker technique is that it consists of two signal stages: The first “orientation stage” is a short but intensive flicker stimulus to attract the attention to elements of interest. Subsequently, the intensive flicker is reduced to a minimally disturbing luminance oscillation (“engagement stage”) as visual support to keep track of the focus elements. To find a good trade-off between attraction effectiveness and subjective annoyance caused by flicker, we conducted two perceptual studies to find suitable signal parameters. We showcase Attractive Flicker with the parameters obtained from the perceptual statistics in a study of molecular interactions. With Attractive Flicker, users were able to easily follow the narrative of the visualization on a large display, while the flickering of focus elements was not disturbing when observing the context.},
	pages = {2456--2465},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Waldner, M. and Muzic, M. Le and Bernhard, M. and Purgathofer, W. and Viola, I.},
	date = {2014-12},
	keywords = {attention attraction, attention guidance, attraction effectiveness, Attractive Flicker technique, brightness, Context awareness, context suppression, Data models, data visualisation, Data visualization, dynamic narrative visualizations, engagement stage, flicker, focus elements, focus-plus-context techniques, human factors, Image color analysis, large-dynamic scene, minimally-disturbing luminance oscillation, minimal visual deformation, molecular interactions, Narrative visualization, Observers, orientation stage, perceptual statistics, perceptual studies, short-intensive flicker stimulus, signal parameters, signal stages, Social network services, subjective annoyance, subjective disturbance, visual attention, visual attractor, visual feature, visual field, visual guidance, Visual Perception, visual prominence, visual support, wait for reading},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PWWPFMH8/6876019.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/HTXIV8XC/Waldner 等. - 2014 - Attractive Flicker #x2014\; Guiding Attention in Dy.pdf:application/pdf}
}

@article{segel_narrative_2010,
	title = {Narrative Visualization: Telling Stories with Data},
	volume = {16},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.179},
	shorttitle = {Narrative Visualization},
	abstract = {Data visualization is regularly promoted for its ability to reveal stories within data, yet these “data stories” differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.},
	pages = {1139--1148},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Segel, E. and Heer, J.},
	date = {2010-11},
	keywords = {case study, data story, data visualisation, Data visualization, design differences, design methods, Economics, educational aids, educational media, Engineering profession, humanities, Image color analysis, journalism, journalistic storytelling, Media, Narrative visualization, online journalists, social data analysis, storytelling, telling story, Visualization, visualization research},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U27TTCX3/5613452.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/39W6GJEG/Segel 和 Heer - 2010 - Narrative Visualization Telling Stories with Data.pdf:application/pdf}
}

@article{satyanarayan_authoring_2014,
	title = {Authoring Narrative Visualizations with Ellipsis},
	volume = {33},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/cgf.12392/abstract},
	doi = {10.1111/cgf.12392},
	abstract = {Data visualization is now a popular medium for journalistic storytelling. However, current visualization tools either lack support for storytelling or require significant technical expertise. Informed by interviews with journalists, we introduce a model of storytelling abstractions that includes state-based scene structure, dynamic annotations and decoupled coordination of multiple visualization components. We instantiate our model in Ellipsis: a system that combines a domain-specific language ({DSL}) for storytelling with a graphical interface for story authoring. User interactions are automatically translated into statements in the Ellipsis {DSL}. By enabling storytelling without programming, the Ellipsis interface lowers the threshold for authoring narrative visualizations. We evaluate Ellipsis through example applications and user studies with award-winning journalists. Study participants find Ellipsis to be a valuable prototyping tool that can empower journalists in the creation of interactive narratives.},
	pages = {361--370},
	number = {3},
	journaltitle = {Computer Graphics Forum},
	shortjournal = {Computer Graphics Forum},
	author = {Satyanarayan, Arvind and Heer, Jeffrey},
	urldate = {2017-01-22},
	date = {2014-06-01},
	langid = {english},
	keywords = {Categories and Subject Descriptors (according to {ACM} {CCS}):, H.5.2 [Information Interfaces]: User Interfaces—{GUI}},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7IU5GSSM/Satyanarayan 和 Heer - 2014 - Authoring Narrative Visualizations with Ellipsis.pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/W4GUFF28/abstract.html:text/html}
}

@inproceedings{huber_visualizing_2005,
	title = {Visualizing data with motion},
	doi = {10.1109/VISUAL.2005.1532838},
	abstract = {This paper describes an experimental study of three perceptual properties of motion: flicker, direction, and velocity. Our goal is to understand how to apply these properties to represent data in a visualization environment. Results from our experiments show that all three properties can encode multiple data values, but that minimum visual differences are needed to ensure rapid and accurate target detection: flicker must be coherent and must have a cycle length of 120 milliseconds or greater, direction must differ by at least 20°, and velocity must differ by at least 0.43° of subtended visual angle. We conclude with an overview of how we are applying our results to real-world data, and then discuss future work we plan to pursue.},
	eventtitle = {{VIS} 05. {IEEE} Visualization, 2005.},
	pages = {527--534},
	booktitle = {{VIS} 05. {IEEE} Visualization, 2005.},
	author = {Huber, D. E. and Healey, C. G.},
	date = {2005-10},
	keywords = {Computer Graphics, data visualisation, Data visualization, direction property, flicker property, Guidelines, Humans, Image analysis, Image converters, image motion analysis, Information analysis, motion perceptual property, Multidimensional systems, Performance analysis, velocity property, Visual system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U656WWGJ/1532838.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/BAQQQBV2/Huber 和 Healey - 2005 - Visualizing data with motion.pdf:application/pdf}
}

@book{munzner_visualization_2014,
	title = {Visualization Analysis and Design},
	isbn = {978-1-4665-0893-4},
	abstract = {Learn How to Design Effective Visualization Systems Visualization Analysis and Design provides a systematic, comprehensive framework for thinking about visualization in terms of principles and design choices. The book features a unified approach encompassing information visualization techniques for abstract data, scientific visualization techniques for spatial data, and visual analytics techniques for interweaving data transformation and analysis with interactive visual exploration. It emphasizes the careful validation of effectiveness and the consideration of function before form.   The book breaks down visualization design according to three questions: what data users need to see, why users need to carry out their tasks, and how the visual representations proposed can be constructed and manipulated. It walks readers through the use of space and color to visually encode data in a view, the trade-offs between changing a single view and using multiple linked views, and the ways to reduce the amount of data shown in each view. The book concludes with six case studies analyzed in detail with the full framework.  The book is suitable for a broad set of readers, from beginners to more experienced visualization designers. It does not assume any previous experience in programming, mathematics, human–computer interaction, or graphic design and can be used in an introductory visualization course at the graduate or undergraduate level.},
	pagetotal = {422},
	publisher = {{CRC} Press},
	author = {Munzner, Tamara},
	date = {2014-12-01},
	langid = {english},
	note = {Google-Books-{ID}: {dznSBQAAQBAJ}},
	keywords = {Business \& Economics / Statistics, Computers / Computer Graphics, Computers / Databases / General, Computers / General, Computers / Social Aspects / Human-Computer Interaction, Technology \& Engineering / Industrial Health \& Safety}
}

@article{heer_animated_2007,
	title = {Animated Transitions in Statistical Data Graphics},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70539},
	abstract = {In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in {DynaVis}, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.},
	pages = {1240--1247},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Heer, J. and Robertson, G.},
	date = {2007-11},
	keywords = {animated transitions, Animation, bar charts, Collaboration, computer animation, data visualisation, Data visualization, design, Drilling, {DynaVis}, experiment, graphical perception, Graphics, Guidelines, Information analysis, information visualization, Marketing and sales, pie charts, Scattering, scatter plots, statistical analysis, statistical data graphics, Taxonomy, transitions, visualization system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TID3N57S/4376146.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/XA2X2EUJ/Heer 和 Robertson - 2007 - Animated Transitions in Statistical Data Graphics.pdf:application/pdf}
}

@inproceedings{figueiras_narrative_2014,
	title = {Narrative Visualization: A Case Study of How to Incorporate Narrative Elements in Existing Visualizations},
	doi = {10.1109/IV.2014.79},
	shorttitle = {Narrative Visualization},
	abstract = {Stories have long been used to convey information, cultural values, and experiences. Narratives not only have been the main way people make sense of the world, but also have been the easiest way humans found out to share complex information. However, today we are confronted with the problem of the amount of information available, which sometimes is hard to cope with. Combining storytelling with visualization has been pointed out as an efficient method to represent and make sense of data, at the same time allowing people to relate with the information. In this paper, we explore the benefits of adding storytelling to visualizations. Drawing on case studies from news media to visualization research websites, we identified possible strategies to introduce storytelling in visualizations such as adding short stories or narrative elements using annotations and using time to introduce the feeling of storytelling or story-flow.},
	eventtitle = {2014 18th International Conference on Information Visualisation},
	pages = {46--52},
	booktitle = {2014 18th International Conference on Information Visualisation},
	author = {Figueiras, A.},
	date = {2014-07},
	keywords = {case study, complex information, Complexity theory, Context, data visualisation, Data visualization, history, humanities, Media, narrative elements, Narrative visualization, news media, Rhetoric, story-flow, storytelling, Visualization, visualization research Web sites, Web sites},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/75MBWM3A/6902879.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/F5TAAV5B/Figueiras - 2014 - Narrative Visualization A Case Study of How to In.pdf:application/pdf}
}

@article{cohn_visual_2013,
	title = {Visual Narrative Structure},
	volume = {37},
	issn = {1551-6709},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/cogs.12016/abstract},
	doi = {10.1111/cogs.12016},
	abstract = {Narratives are an integral part of human expression. In the graphic form, they range from cave paintings to Egyptian hieroglyphics, from the Bayeux Tapestry to modern day comic books (Kunzle, 1973; {McCloud}, 1993). Yet not much research has addressed the structure and comprehension of narrative images, for example, how do people create meaning out of sequential images? This piece helps fill the gap by presenting a theory of Narrative Grammar. We describe the basic narrative categories and their relationship to a canonical narrative arc, followed by a discussion of complex structures that extend beyond the canonical schema. This demands that the canonical arc be reconsidered as a generative schema whereby any narrative category can be expanded into a node in a tree structure. Narrative “pacing” is interpreted as a reflection of various patterns of this embedding: conjunction, left-branching trees, center-embedded constituencies, and others. Following this, diagnostic methods are proposed for testing narrative categories and constituency. Finally, we outline the applicability of this theory beyond sequential images, such as to film and verbal discourse, and compare this theory with previous approaches to narrative and discourse.},
	pages = {413--452},
	number = {3},
	journaltitle = {Cognitive Science},
	author = {Cohn, Neil},
	urldate = {2017-01-22},
	date = {2013-04-01},
	langid = {english},
	keywords = {Comics, Discourse, Film, narrative, Visual language},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/AG2ZA3IB/Cohn - 2013 - Visual Narrative Structure.pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4G27ME96/abstract.html:text/html}
}

@article{gershon_what_2001,
	title = {What Storytelling Can Do for Information Visualization},
	volume = {44},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/381641.381653},
	doi = {10.1145/381641.381653},
	pages = {31--37},
	number = {8},
	journaltitle = {Commun. {ACM}},
	author = {Gershon, Nahum and Page, Ward},
	urldate = {2017-01-23},
	date = {2001-08},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U4UN98DF/Gershon 和 Page - 2001 - What Storytelling Can Do for Information Visualiza.pdf:application/pdf}
}

@online{_practical_????,
	title = {A Practical Iterative Framework for Qualitative Data Analysis},
	url = {http://journals.sagepub.com/doi/pdf/10.1177/160940690900800107},
	urldate = {2017-01-23},
	file = {160940690900800107.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/B5GXSKAX/160940690900800107.pdf:application/pdf}
}

@article{mackinlay_show_2007,
	title = {Show Me: Automatic Presentation for Visual Analysis},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70594},
	shorttitle = {Show Me},
	abstract = {This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is {VizQL}, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.},
	pages = {1137--1144},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Mackinlay, J. and Hanrahan, P. and Stolte, C.},
	date = {2007-11},
	keywords = {algebraic specification, algebraic specification language, automatic presentation, Best practices, Computer Graphics, data analysis, data visualisation, Data visualization, Displays, Encoding, Expert Systems, graphic design, Graphics, Information analysis, Information Storage and Retrieval, Programming Languages, small multiple display, small multiples., Software, Software Design, specification languages, User-Computer Interface, user interface, user interfaces, visual analysis, visual analysis system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IC5VQG6D/4376133.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4AJM5853/Mackinlay 等. - 2007 - Show Me Automatic Presentation for Visual Analysi.pdf:application/pdf}
}

@online{schmidt_living_2017,
	title = {the living handbook of narratology},
	author = {Schmidt, Johann N.},
	date = {2017-01-23},
	file = {Narration in Film - the living handbook of narratology:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/V5BDPHIN/index.html:text/html}
}

@inproceedings{amini_understanding_2015,
	location = {New York, {NY}, {USA}},
	title = {Understanding Data Videos: Looking at Narrative Visualization Through the Cinematography Lens},
	isbn = {978-1-4503-3145-6},
	url = {http://doi.acm.org/10.1145/2702123.2702431},
	doi = {10.1145/2702123.2702431},
	series = {{CHI} '15},
	shorttitle = {Understanding Data Videos},
	abstract = {Data videos, motion graphics that incorporate visualizations about facts, are increasingly gaining popularity as a means of telling stories with data. However, very little is systematically recorded about (a) what elements are featured in data videos and (b) the processes used to create them. In this article, we provide initial insights to build this knowledge. We first report on a qualitative analysis of 50 professionally designed data videos, extracting and exposing their most salient constituents. Second, we report on a series of workshops with experienced storytellers from cinematography, graphics design and screenplay writing. We provided them with a set of data facts and visualizations and observed them create storyboards for data videos. From these exploratory studies, we derive broader implications for the design of an authoring tool to enable a wide audience to create data videos. Our findings highlight the importance of providing a flexible tool supporting a non-linear creation process and allowing users to iteratively go back to different phases of the process.},
	pages = {1459--1468},
	booktitle = {Proceedings of the 33rd Annual {ACM} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {Amini, Fereshteh and Henry Riche, Nathalie and Lee, Bongshin and Hurter, Christophe and Irani, Pourang},
	urldate = {2017-01-23},
	date = {2015},
	keywords = {data storytelling, data video, information visualization, Narrative visualization, qualitative analysis},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/K3FZI78A/Amini 等. - 2015 - Understanding Data Videos Looking at Narrative Vi.pdf:application/pdf}
}

@article{liu_online_2016,
	title = {Online Visual Analytics of Text Streams},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2509990},
	abstract = {We present an online visual analytics approach to helping users explore and understand hierarchical topic evolution in high-volume text streams. The key idea behind this approach is to identify representative topics in incoming documents and align them with the existing representative topics that they immediately follow (in time). To this end, we learn a set of streaming tree cuts from topic trees based on user-selected focus nodes. A dynamic Bayesian network model has been developed to derive the tree cuts in the incoming topic trees to balance the fitness of each tree cut and the smoothness between adjacent tree cuts. By connecting the corresponding topics at different times, we are able to provide an overview of the evolving hierarchical topics. A sedimentation-based visualization has been designed to enable the interactive analysis of streaming text data from global patterns to local details. We evaluated our method on real-world datasets and the results are generally favorable.},
	pages = {2451--2466},
	number = {11},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Liu, S. and Yin, J. and Wang, X. and Cui, W. and Cao, K. and Pei, J.},
	date = {2016-11},
	keywords = {adjacent tree cuts, Algorithm design and analysis, Bayes methods, belief networks, Clustering algorithms, data analysis, data visualisation, Data visualization, dynamic Bayesian network model, Electronic mail, evolutionary tree clustering, global patterns, Heuristic algorithms, hierarchical topic evolution, high-volume text streams, interactive analysis, online visual analytics, sedimentation-based visualization, streaming text data, streaming topic visualization, streaming tree cut, streaming tree cuts, text analysis, topic trees, user-selected focus nodes, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QBJ5WP3B/7360233.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/8QFJ6VKD/Liu 等. - 2016 - Online Visual Analytics of Text Streams.pdf:application/pdf}
}

@article{huron_visual_2013,
	title = {Visual Sedimentation},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.227},
	abstract = {We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, {RSS}, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.},
	pages = {2446--2455},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Huron, S. and Vuillemot, R. and Fekete, J. D.},
	date = {2013-12},
	keywords = {Algorithms, chronological order, Computer Graphics, Computer Simulation, data stream, data stream visualization, data visualisation, Data visualization, design, Design methodology, dynamic data, dynamic visualization, force model, Geologic Sediments, Image Enhancement, Information Storage and Retrieval, information visualization, metaphor, metaphor design space, Models, Theoretical, real time, Real-time systems, Reproducibility of Results, sedimentation process, Sediments, Sensitivity and Specificity, User-Computer Interface, visual sedimentation design metaphor},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RZ8M9FPZ/6634152.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/5MM2GSXM/Huron 等. - 2013 - Visual Sedimentation.pdf:application/pdf}
}

@article{lee_sketchstory:_2013,
	title = {{SketchStory}: Telling More Engaging Stories with Data through Freeform Sketching},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.191},
	shorttitle = {{SketchStory}},
	abstract = {Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present {SketchStory}, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. {SketchStory} recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, {SketchStory} allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare {SketchStory} with a traditional presentation system, Microsoft {PowerPoint}. Results show that the audience is more engaged by presentations done with {SketchStory} than {PowerPoint}. Eighteen out of 24 audience participants preferred {SketchStory} to {PowerPoint}. Four out of five presenter participants also favored {SketchStory} despite the extra effort required for presentation.},
	pages = {2416--2425},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Lee, B. and Kazi, R. H. and Smith, G.},
	date = {2013-12},
	keywords = {Algorithms, Animation, computer animation, Computer Graphics, data charts, data-enabled digital whiteboard, data exploration, data presentation, data visualisation, Data visualization, Filtering, freeform sketching, gesture recognition, Image Enhancement, Information Dissemination, information visualization, Interaction, Microsoft {PowerPoint}, Narration, narrative storytelling attributes, Paintings, pen and touch, pen-and-touch interactions, presenter-provided example icon, Real-time systems, Rendering (computer graphics), sketch, sketch gestures, {SketchStory}, storytelling, User-Computer Interface, Visualization, whiteboard animation},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/W9G4MPE3/6634113.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/BI4FPZJ6/Lee 等. - 2013 - SketchStory Telling More Engaging Stories with Da.pdf:application/pdf}
}

@article{itti_computational_2001,
	title = {Computational modelling of visual attention},
	volume = {2},
	rights = {© 2001 Nature Publishing Group},
	issn = {1471-003X},
	url = {http://www.nature.com/nrn/journal/v2/n3/abs/nrn0301_194a.html},
	doi = {10.1038/35058500},
	abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
	pages = {194--203},
	number = {3},
	journaltitle = {Nature Reviews Neuroscience},
	shortjournal = {Nat Rev Neurosci},
	author = {Itti, Laurent and Koch, Christof},
	urldate = {2017-02-05},
	date = {2001-03},
	langid = {english},
	file = {Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2INAP2CG/nrn0301_194a.html:text/html}
}

@article{walther_modeling_2006,
	title = {Modeling attention to salient proto-objects},
	volume = {19},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608006002152},
	doi = {10.1016/j.neunet.2006.10.001},
	series = {Brain and {AttentionBrain} and Attention},
	abstract = {Selective visual attention is believed to be responsible for serializing visual information for recognizing one object at a time in a complex scene. But how can we attend to objects before they are recognized? In coherence theory of visual cognition, so-called proto-objects form volatile units of visual information that can be accessed by selective attention and subsequently validated as actual objects. We propose a biologically plausible model of forming and attending to proto-objects in natural scenes. We demonstrate that the suggested model can enable a model of object recognition in cortex to expand from recognizing individual objects in isolation to sequentially recognizing all objects in a more complex scene.},
	pages = {1395--1407},
	number = {9},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Walther, Dirk and Koch, Christof},
	urldate = {2017-02-05},
	date = {2006-11},
	keywords = {Attention model, Object recognition, Proto-objects, visual attention},
	file = {ScienceDirect Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2TKBZ3HU/Walther 和 Koch - 2006 - Modeling attention to salient proto-objects.pdf:application/pdf;ScienceDirect Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/FEXJX7ZX/S0893608006002152.html:text/html}
}

@article{itti_model_1998,
	title = {A model of saliency-based visual attention for rapid scene analysis},
	volume = {20},
	issn = {0162-8828},
	doi = {10.1109/34.730558},
	abstract = {A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail},
	pages = {1254--1259},
	number = {11},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Itti, L. and Koch, C. and Niebur, E.},
	date = {1998-11},
	keywords = {Biological system modeling, Brain modeling, Computer architecture, computer vision, dynamical neural network, Feature extraction, Hardware, Image analysis, image recognition, Layout, neural nets, Neural networks, Object detection, rapid scene analysis, saliency, scene understanding, target detection, Target tracking, topographical saliency map, visual attention, visual search, Visual system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/M3T26GMD/730558.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IIST39BC/Itti 等. - 1998 - A model of saliency-based visual attention for rap.pdf:application/pdf}
}

@article{petersen_attention_2012,
	title = {The Attention System of the Human Brain: 20 Years After},
	volume = {35},
	issn = {0147-006X},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3413263/},
	doi = {10.1146/annurev-neuro-062111-150525},
	shorttitle = {The Attention System of the Human Brain},
	abstract = {Here, we update our 1990 Annual Review of Neuroscience article, “The Attention System of the Human Brain.” The framework presented in the original article has helped to integrate behavioral, systems, cellular, and molecular approaches to common problems in attention research. Our framework has been both elaborated and expanded in subsequent years. Research on orienting and executive functions has supported the addition of new networks of brain regions. Developmental studies have shown important changes in control systems between infancy and childhood. In some cases, evidence has supported the role of specific genetic variations, often in conjunction with experience, that account for some of the individual differences in the efficiency of attentional networks. The findings have led to increased understanding of aspects of pathology and to some new interventions.},
	pages = {73--89},
	journaltitle = {Annual review of neuroscience},
	shortjournal = {Annu Rev Neurosci},
	author = {Petersen, Steven E. and Posner, Michael I.},
	urldate = {2017-02-06},
	date = {2012-07-21},
	pmid = {22524787},
	pmcid = {PMC3413263},
	file = {PubMed Central Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DACDKU8B/Petersen 和 Posner - 2012 - The Attention System of the Human Brain 20 Years .pdf:application/pdf}
}

@article{itti_models_????,
	title = {Models of Bottom-Up Attention and Saliency},
	url = {http://s3.amazonaws.com/academia.edu.documents/30739887/10.1.1.76.9678.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1486353112&Signature=gcrhG89T9As1%2FTquEQ0ZTCythGE%3D&response-content-disposition=inline%3B%20filename%3DModels_of_bottom-up_attention_and_salien.pdf},
	author = {Itti, Laurent},
	urldate = {2017-02-06},
	file = {10.1.1.76.9678.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PUDXAP4V/10.1.1.76.9678.pdf:application/pdf}
}

@book{munzner_visualization_2014-1,
	title = {Visualization Analysis and Design},
	isbn = {978-1-4665-0893-4},
	abstract = {Learn How to Design Effective Visualization Systems Visualization Analysis and Design provides a systematic, comprehensive framework for thinking about visualization in terms of principles and design choices. The book features a unified approach encompassing information visualization techniques for abstract data, scientific visualization techniques for spatial data, and visual analytics techniques for interweaving data transformation and analysis with interactive visual exploration. It emphasizes the careful validation of effectiveness and the consideration of function before form.   The book breaks down visualization design according to three questions: what data users need to see, why users need to carry out their tasks, and how the visual representations proposed can be constructed and manipulated. It walks readers through the use of space and color to visually encode data in a view, the trade-offs between changing a single view and using multiple linked views, and the ways to reduce the amount of data shown in each view. The book concludes with six case studies analyzed in detail with the full framework.  The book is suitable for a broad set of readers, from beginners to more experienced visualization designers. It does not assume any previous experience in programming, mathematics, human–computer interaction, or graphic design and can be used in an introductory visualization course at the graduate or undergraduate level.},
	pagetotal = {422},
	publisher = {{CRC} Press},
	author = {Munzner, Tamara},
	date = {2014-12-01},
	langid = {english},
	note = {Google-Books-{ID}: {dznSBQAAQBAJ}},
	keywords = {Business \& Economics / Statistics, Computers / Computer Graphics, Computers / Databases / General, Computers / General, Computers / Social Aspects / Human-Computer Interaction, Technology \& Engineering / Industrial Health \& Safety}
}

@article{itti_saliency-based_2000,
	title = {A saliency-based search mechanism for overt and covert shifts of visual attention},
	volume = {40},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698999001637},
	doi = {10.1016/S0042-6989(99)00163-7},
	abstract = {Most models of visual search, whether involving overt eye movements or covert shifts of attention, are based on the concept of a saliency map, that is, an explicit two-dimensional map that encodes the saliency or conspicuity of objects in the visual environment. Competition among neurons in this map gives rise to a single winning location that corresponds to the next attended target. Inhibiting this location automatically allows the system to attend to the next most salient location. We describe a detailed computer implementation of such a scheme, focusing on the problem of combining information across modalities, here orientation, intensity and color information, in a purely stimulus-driven manner. The model is applied to common psychophysical stimuli as well as to a very demanding visual search task. Its successful performance is used to address the extent to which the primate visual system carries out visual search via one or more such saliency maps and how this can be tested.},
	pages = {1489--1506},
	number = {10},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Itti, Laurent and Koch, Christof},
	urldate = {2017-02-06},
	date = {2000-06},
	keywords = {saliency, Vision systems, visual attention},
	file = {ScienceDirect Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/37F8X2U4/Itti 和 Koch - 2000 - A saliency-based search mechanism for overt and co.pdf:application/pdf;ScienceDirect Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/JGP6QZ3J/S0042698999001637.html:text/html}
}

@article{satyanarayan_vega-lite:_2017,
	title = {Vega-Lite: A Grammar of Interactive Graphics},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2599030},
	shorttitle = {Vega-Lite},
	abstract = {We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.},
	pages = {341--350},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Satyanarayan, A. and Moritz, D. and Wongsuphasawat, K. and Heer, J.},
	date = {2017-01},
	keywords = {Brushes, composition algebra, conditional logic, customized interaction methods, data visualisation, Data visualization, declarative specification, Encoding, Grammar, grammars, high-level grammar, inclusion testing, information visualization, Interaction, interactive data visualizations, interactive graphics, interactive systems, linked selection, multiview displays, program compilers, systems, toolkits, Transforms, Vega-Lite compiler, visual encoding rules, visual encodings, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/VA8N4XJX/7539624.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/99KHKM7J/Satyanarayan 等. - 2017 - Vega-Lite A Grammar of Interactive Graphics.pdf:application/pdf}
}

@inproceedings{callahan_vistrails:_2006,
	location = {New York, {NY}, {USA}},
	title = {{VisTrails}: Visualization Meets Data Management},
	isbn = {978-1-59593-434-5},
	url = {http://doi.acm.org/10.1145/1142473.1142574},
	doi = {10.1145/1142473.1142574},
	series = {{SIGMOD} '06},
	shorttitle = {{VisTrails}},
	abstract = {Scientists are now faced with an incredible volume of data to analyze. To successfully analyze and validate various hypothesis, it is necessary to pose several queries, correlate disparate data, and create insightful visualizations of both the simulated processes and observed phenomena. Often, insight comes from comparing the results of multiple visualizations. Unfortunately, today this process is far from interactive and contains many error-prone and time-consuming tasks. As a result, the generation and maintenance of visualizations is a major bottleneck in the scientific process, hindering both the ability to mine scientific data and the actual use of the data. The {VisTrails} system represents our initial attempt to improve the scientific discovery process and reduce the time to insight. In {VisTrails}, we address the problem of visualization from a data management perspective: {VisTrails} manages the data and metadata of a visualization product. In this demonstration, we show the power and flexibility of our system by presenting actual scenarios in which scientific visualization is used and showing how our system improves usability, enables reproducibility, and greatly reduces the time required to create scientific visualizations.},
	pages = {745--747},
	booktitle = {Proceedings of the 2006 {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {{ACM}},
	author = {Callahan, Steven P. and Freire, Juliana and Santos, Emanuele and Scheidegger, Carlos E. and Silva, Cláudio T. and Vo, Huy T.},
	urldate = {2017-02-09},
	date = {2006},
	keywords = {data provenance, scientific dataflows, Visualization},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WIEP55QN/Callahan 等. - 2006 - VisTrails Visualization Meets Data Management.pdf:application/pdf}
}

@article{heer_animated_2007-1,
	title = {Animated Transitions in Statistical Data Graphics},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70539},
	abstract = {In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in {DynaVis}, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.},
	pages = {1240--1247},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Heer, J. and Robertson, G.},
	date = {2007-11},
	keywords = {animated transitions, Animation, bar charts, Collaboration, computer animation, data visualisation, Data visualization, design, Drilling, {DynaVis}, experiment, graphical perception, Graphics, Guidelines, Information analysis, information visualization, Marketing and sales, pie charts, Scattering, scatter plots, statistical analysis, statistical data graphics, Taxonomy, transitions, visualization system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CJ2WNHS2/4376146.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6RJPF67W/Heer 和 Robertson - 2007 - Animated Transitions in Statistical Data Graphics.pdf:application/pdf}
}

@inproceedings{wang_animated_2016,
	location = {New York, {NY}, {USA}},
	title = {Animated Narrative Visualization for Video Clickstream Data},
	isbn = {978-1-4503-4547-7},
	url = {http://doi.acm.org/10.1145/3002151.3002155},
	doi = {10.1145/3002151.3002155},
	series = {{SA} '16},
	abstract = {Video clickstream data are important for understanding user behaviors and improving online video services. Various visual analytics techniques have been proposed to explore patterns in these data. However, those techniques are mainly developed for analysis and do not sufficiently support presentations. It is still difficult for data analysts to convey their findings to an audience without prior knowledge. In this paper, we propose to use animated narrative visualization to present video clickstream data. Compared with traditional methods which directly turn click events into animations, our animated narrative visualization focuses on conveying the patterns in the data to a general audience and adopts two novel designs, non-linear time mapping and foreshadowing, to make the presentation more engaging and interesting. Our non-linear time mapping method keeps the interesting parts as the focus of the animation while compressing the uninteresting parts as the context. The foreshadowing techniques can engage the audience and alert them to the events in the animation. Our user study indicates the effectiveness of our system and provides guidelines for the design of similar systems.},
	pages = {11:1--11:8},
	booktitle = {{SIGGRAPH} {ASIA} 2016 Symposium on Visualization},
	publisher = {{ACM}},
	author = {Wang, Yun and Chen, Zhutian and Li, Quan and Ma, Xiaojuan and Luo, Qiong and Qu, Huamin},
	urldate = {2017-02-20},
	date = {2016},
	keywords = {animated visualization, clickstream data, data storytelling, Narrative visualization},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WMW786DZ/Wang 等. - 2016 - Animated Narrative Visualization for Video Clickst.pdf:application/pdf}
}

@article{ruchikachorn_learning_2015,
	title = {Learning Visualizations by Analogy: Promoting Visual Literacy through Visualization Morphing},
	volume = {21},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2413786},
	shorttitle = {Learning Visualizations by Analogy},
	abstract = {We propose the concept of teaching (and learning) unfamiliar visualizations by analogy, that is, demonstrating an unfamiliar visualization method by linking it to another more familiar one, where the in-betweens are designed to bridge the gap of these two visualizations and explain the difference in a gradual manner. As opposed to a textual description, our morphing explains an unfamiliar visualization through purely visual means. We demonstrate our idea by ways of four visualization pair examples: data table and parallel coordinates, scatterplot matrix and hyperbox, linear chart and spiral chart, and hierarchical pie chart and treemap. The analogy is commutative i.e. any member of the pair can be the unfamiliar visualization. A series of studies showed that this new paradigm can be an effective teaching tool. The participants could understand the unfamiliar visualization methods in all of the four pairs either fully or at least significantly better after they observed or interacted with the transitions from the familiar counterpart. The four examples suggest how helpful visualization pairings be identified and they will hopefully inspire other visualization morphings and associated transition strategies to be identified.},
	pages = {1028--1044},
	number = {9},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Ruchikachorn, P. and Mueller, K.},
	date = {2015-09},
	keywords = {Animation, associated transition strategy, computer literacy, computer science education, data table, data visualisation, Data visualization, Education, hierarchical pie chart, hyperbox, information visualization, Interaction, Joining processes, Layout, linear chart, Literacy, Multivariate Visualization, parallel coordinates, scatterplot matrix, spiral chart, Spirals, teaching, textual description, treemap, unfamiliar visualization teaching method, Visualization, visualization by analogy learning, visualization morphing, visual literacy},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/99TX3NQB/7061477.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/557U9WKG/Ruchikachorn 和 Mueller - 2015 - Learning Visualizations by Analogy Promoting Visu.pdf:application/pdf}
}